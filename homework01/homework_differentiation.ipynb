{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GNhRw3Y7Cfu"
   },
   "source": [
    "# Homework 1: Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_eYH-zE17Cfz"
   },
   "source": [
    "Since it easy to google every task please please please try to undestand what's going on. The \"just answer\" thing will be not counted, make sure to present derivation of your solution. It is absolutely OK if you found an answer on web then just exercise in $\\LaTeX$ copying it into here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7vy1GJv7Cf2"
   },
   "source": [
    "Useful links: \n",
    "[1](http://www.machinelearning.ru/wiki/images/2/2a/Matrix-Gauss.pdf)\n",
    "[2](http://www.atmos.washington.edu/~dennis/MatrixCalculus.pdf)\n",
    "[3](http://cal.cs.illinois.edu/~johannes/research/matrix%20calculus.pdf)\n",
    "[4](http://research.microsoft.com/en-us/um/people/cmbishop/prml/index.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCWP-SVF7Cf3"
   },
   "source": [
    "## ex. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpudYy2R7Cf6"
   },
   "source": [
    "$$  \n",
    "y = x^Tx,  \\quad x \\in \\mathbb{R}^N \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YbL0EUoK7Cf7"
   },
   "source": [
    "$$\n",
    "\\frac{dy}{dx} = \\Big( \\frac{d(x_1^2 + x_2^2 + \\ldots)}{dx_1}, \\frac{d(x_1^2 + x_2^2 + \\ldots)}{dx_2}, ...\\Big) = \\Big( 2x_1, 2x_2, \\ldots \\Big) = 2x^T\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilu23mhP7CgG"
   },
   "source": [
    "## ex. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rzWDWte7CgJ"
   },
   "source": [
    "$$ y = tr(AB) \\quad A,B \\in \\mathbb{R}^{N \\times N} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BjAPBaOB7CgK"
   },
   "source": [
    "$$\n",
    "\\frac{dy}{dA} = \\frac{d}{dA} (\\sum_{i}{a_{1i} b_{i1}} + \\sum_{i}{a_{2i} b_{i2}} + \\ldots)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow \\frac{d}{da_{ij}} (\\sum_{i}{a_{1i} b_{i1}} + \\sum_{i}{a_{2i} b_{i2}} + \\ldots) = b_{ji}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow \\frac{dy}{dA} = B^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5BqqH0tu7CgT"
   },
   "source": [
    "## ex. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V-ZYWXqV7CgV"
   },
   "source": [
    "$$  \n",
    "y = x^TAc , \\quad A\\in \\mathbb{R}^{N \\times N}, x\\in \\mathbb{R}^{N}, c\\in \\mathbb{R}^{N} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $y$ scalar:\n",
    "\n",
    "$$\n",
    "y = y^T = c^T A^T x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using:\n",
    "$$\n",
    "\\frac{dAx}{dx} = A\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhupLT9s7CgX"
   },
   "source": [
    "$$\n",
    "\\Rightarrow \\frac{dy}{dx} = \\frac{d((c^TA^T)x)}{dx} = c^TA^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0PZovng7CgZ"
   },
   "source": [
    "$$\n",
    "\\frac{dy}{dA} = \\frac{d}{dA} \\Big( (\\sum_{i}{x_ia_{i1}}, \\sum_{i}{x_i a_{i2}}, \\ldots) \\cdot (c_1, c_2, ..)^T \\Big)\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\ = \\frac{d}{dA} \\Big( c_1 \\sum_{i}{x_ia_{i1}} + c_2 \\sum_{i}{x_i a_{i2}} + \\ldots  \\Big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow \\frac{dy}{da_{ij}} = x_i c_j\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow \\frac{dy}{dA} = xc^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvnPKSPL7Cgl"
   },
   "source": [
    "## ex. 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaxIa3NB7Cgo"
   },
   "source": [
    "Classic matrix factorization example. Given matrix $X$ you need to find $A$, $S$ to approximate $X$. This can be done by simple gradient descent iteratively alternating $A$ and $S$ updates.\n",
    "$$\n",
    "J = || X - AS ||_F^2  , \\quad A\\in \\mathbb{R}^{N \\times R} , \\quad S\\in \\mathbb{R}^{R \\times M}\n",
    "$$\n",
    "$$\n",
    "\\frac{dJ}{dS} = ? \n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eg8Q9k8V7Cgr"
   },
   "source": [
    "### First approach\n",
    "Using ex.2 and the fact:\n",
    "$$\n",
    "|| X ||_F^2 = tr(XX^T) \n",
    "$$ \n",
    "it is easy to derive gradients (you can find it in one of the refs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "0yOxEkqE7Cgt"
   },
   "source": [
    "### Second approach\n",
    "You can use *slightly different techniques* if they suits you. Take a look at this derivation:\n",
    "<img src=\"https://github.com/dimaischenko/Practical_DL/blob/spring2019_solutions/homework01/grad.png?raw=1\">\n",
    "(excerpt from [Handbook of blind source separation, Jutten, page 517](https://books.google.ru/books?id=PTbj03bYH6kC&printsec=frontcover&dq=Handbook+of+Blind+Source+Separation&hl=en&sa=X&ved=0ahUKEwi-q_apiJDLAhULvXIKHVXJDWcQ6AEIHDAA#v=onepage&q=Handbook%20of%20Blind%20Source%20Separation&f=false), open for better picture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "EqWH5KPq7Cgv"
   },
   "source": [
    "### Third approach\n",
    "And finally we can use chain rule! **YOUR TURN** to do it.\n",
    "let $ F = AS $ \n",
    "\n",
    "**Find**\n",
    "$$\n",
    "\\frac{dJ}{dF} = \\frac{d}{dF} tr \\Big[ (X - F) (X-F)^T\\Big] = \\frac{d}{dF} (tr[XX^T] -2 tr[FX^T] - tr[FF^T])\n",
    "$$ \n",
    "\n",
    "use ex.2\n",
    "\n",
    "$$\n",
    "\\frac{d}{dF} (-2 tr[FX^T]) = -2X\n",
    "$$\n",
    "\n",
    "and simplification: $tr(FF^T) = f_{11}f_{11} + 2f_{12}f_{21} + \\ldots$:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dF} (-tr[FF^T]) = 2F\n",
    "$$\n",
    "\n",
    "so:\n",
    "\n",
    "$$\n",
    "\\frac{dJ}{dF} = -2X + 2F\n",
    "$$\n",
    "Using:\n",
    "$$\n",
    "\\frac{dF}{dS} = A^T\n",
    "$$ \n",
    "\n",
    "Now it is easy do get desired gradients:\n",
    "$$\n",
    "\\frac{dJ}{dS} =  \\frac{dJ}{dF} \\frac{dF}{dS} = (-2X + 2F) A^T = -2XA^T + 2ASA^T\n",
    "$$ "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "homework_differentiation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
